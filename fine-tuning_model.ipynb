{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cc5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "num_workers = 3\n",
    "initial_seed = 0\n",
    "torch.manual_seed(initial_seed)\n",
    "\n",
    "pretrained=True\n",
    "\n",
    "base_path = \"/int_data/house-count\"\n",
    "\n",
    "#train_alias = \"train_a\"\n",
    "train_alias = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b982c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set reproducible executing\n",
    "    \n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26be4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained:\n",
    "#    mean=(0.485, 0.456, 0.406)\n",
    "#    std=(0.229, 0.224, 0.225)\n",
    "    mean = (0.3945,  0.3966, 0.3185)\n",
    "    std = (0.1600, 0.1648, 0.1746)\n",
    "else:    \n",
    "    mean = (0.3945,  0.3966, 0.3185)\n",
    "    std = (0.1600, 0.1648, 0.1746)\n",
    "    \n",
    "resize_val = 256\n",
    "\n",
    "transform_train = A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        A.Flip(),\n",
    "        A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.ISONoise(),\n",
    "            A.GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        #A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=.1),            \n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),            \n",
    "            A.RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "        A.Resize(resize_val, resize_val),\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "transform_valid = A.Compose([        \n",
    "        A.Resize(resize_val, resize_val),\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebdcb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_df, train_alias, transform=None):\n",
    "\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform       \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # достаем имя изображения и ее лейбл\n",
    "        image_name, label = self.data_df.iloc[idx]['img_num'], self.data_df.iloc[idx]['number_of_houses']\n",
    "\n",
    "        # читаем картинку. read the image\n",
    "        image = cv2.imread(f\"{base_path}/{train_alias}/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "              \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image, torch.tensor(label).long()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033d5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(base_path+\"/sample_solution.csv\")\n",
    "test_df = test_df.drop([\"number_of_houses\"], axis = 1)\n",
    "\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, data_df, transform=None):\n",
    "        self.data_df = data_df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data_df.iloc[idx]['img_num']\n",
    "        \n",
    "        # читаем картинку\n",
    "        image = cv2.imread(f\"{base_path}/test/{image_name}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)       \n",
    "        \n",
    "        # преобразуем, если нужно\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd00a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, train_dataloader, test_dataloader, NUM_EPOCH=15):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    \n",
    "    train_acc_log = []\n",
    "    val_acc_log = []\n",
    "    best_model_attr = None\n",
    "    \n",
    "    clear_output()\n",
    "        \n",
    "    \n",
    "    for epoch in tqdm(range(NUM_EPOCH)):\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_size = 0\n",
    "        \n",
    "        train_pred = 0.\n",
    "\n",
    "        for imgs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            #print(imgs.shape)\n",
    "\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_size += y_pred.size(0)\n",
    "            train_loss_log.append(loss.data / y_pred.size(0))\n",
    "            \n",
    "            train_pred += (y_pred.argmax(1) == labels).sum()\n",
    "\n",
    "            optimizer.step()            \n",
    "\n",
    "        train_acc_log.append(train_pred / train_size)\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_size = 0\n",
    "        \n",
    "        val_pred = 0.\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        delta = np.zeros(30)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_dataloader:\n",
    "                \n",
    "                #print(imgs.shape)\n",
    "                \n",
    "                imgs = imgs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_size += pred.size(0)\n",
    "                \n",
    "                indexis = torch.abs(labels - pred.argmax(1)).cpu().detach().numpy() \n",
    "                np.add.at(delta, indexis, 1)                \n",
    "                val_pred += (pred.argmax(1) == labels).sum()\n",
    "        \n",
    "\n",
    "        val_loss_log.append(val_loss / val_size)\n",
    "        val_acc_log.append(val_pred / val_size)\n",
    "\n",
    "        \n",
    "        #plot_history(train_loss_log, val_loss_log, 'loss')\n",
    "        \n",
    "        clear_output()\n",
    "        \n",
    "\n",
    "        print(\"learning rate:\", optimizer.param_groups[0][\"lr\"])\n",
    "        print('Train loss:', (train_loss / train_size)*100)\n",
    "        print('Val loss:', (val_loss / val_size)*100)\n",
    "        print('Train acc:', (train_pred / train_size)*100)\n",
    "        print('Val acc:', (val_pred / val_size)*100)\n",
    "        print('D: ', delta)\n",
    "                        \n",
    "        \n",
    "        d = []\n",
    "        for i in range(6):\n",
    "            if i!=0:\n",
    "                d.append(d[len(d)-1]+delta[i])\n",
    "            else:\n",
    "                d.append(delta[i])\n",
    "                \n",
    "        d = d/delta.sum()\n",
    "        \n",
    "        print('===ERR===\\n        c          b')\n",
    "        \n",
    "        for i in range(len(d)):\n",
    "            if best_model_attr:\n",
    "                print(i, d[i], best_model_attr[2][i])\n",
    "            else:    \n",
    "                print(i, d[i])\n",
    "        \n",
    "        r2_surg = sum([ i*i *delta[i] for i in range(len(delta))])/1000.\n",
    "        \n",
    "        print(\"SUROGAT-R2:\", r2_surg)\n",
    "        if best_model_attr:\n",
    "            print(\"SUROGAT-R2_best:\", best_model_attr[0])\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if best_model_attr is None or best_model_attr[0] > r2_surg:\n",
    "            best_model_attr = (r2_surg, copy.deepcopy(model), d)\n",
    "        \n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log, best_model_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "261bd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    valid_predicts = []\n",
    "\n",
    "    for imgs, label in valid_loader:\n",
    "        \n",
    "        imgs = imgs.cuda()\n",
    "        pred = model(imgs)\n",
    "\n",
    "        pred_numpy = pred.cpu().detach().numpy()\n",
    "\n",
    "        for class_obj in pred_numpy:\n",
    "            index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])            \n",
    "            valid_predicts.append(index)\n",
    "        \n",
    "    return valid_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff2fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fit_model(train_loader, valid_loader, lr, epoch, momentum, milestone, gamma, cycle, gamma_pow, weight_decay):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    model = models.resnet50(pretrained=pretrained)\n",
    "    model.fc = nn.Linear(2048, 25)\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=momentum, weight_decay = weight_decay)\n",
    "\n",
    "    scheduler_instance = scheduler_custom_func (milestone, gamma, cycle, gamma_pow)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = scheduler_instance)\n",
    "\n",
    "    train_loss_log, train_acc_log, val_loss_log, val_acc_log, best_model_attr = train(model, \n",
    "                                                                 criterion, \n",
    "                                                                 optimizer, \n",
    "                                                                 scheduler,\n",
    "                                                                 train_loader, \n",
    "                                                                 valid_loader, \n",
    "                                                                 epoch)\n",
    "    return train_loss_log, train_acc_log, val_loss_log, val_acc_log, best_model_attr , model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eea0f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_models(models, valid_loader, file_log):\n",
    "    r2_vals = []\n",
    "    for ind_m in range(len(models)):\n",
    "    \n",
    "        torch.cuda.empty_cache()\n",
    "        model = models[ind_m]\n",
    "        model.to(\"cuda:0\")\n",
    "    \n",
    "        valid_predicts = valid(model, valid_loader)\n",
    "        valid_df[\"pred\"] = valid_predicts\n",
    "        valid_df['diff'] = valid_df['number_of_houses']-valid_df['pred']\n",
    "\n",
    "        r2 = metrics.r2_score(valid_df['number_of_houses'].values, valid_df['pred'].values)\n",
    "        acc = metrics.accuracy_score(valid_df['number_of_houses'].values, valid_df['pred'].values)\n",
    "        hist_err = valid_df['diff'].value_counts()/valid_df.shape[0]\n",
    "        log_val = f\"\\nmodel {ind_m:d}\"\n",
    "        log_val = log_val + f\"\\nr2: {r2:.4f}\\nacc: {acc:.4f}\"\n",
    "    \n",
    "        log_val = log_val + \"\\n=====errors====\"\n",
    "        d = []\n",
    "        for i in range(6):\n",
    "            if i!=0:\n",
    "                c = d[len(d)-1]\n",
    "                if i in hist_err.index:\n",
    "                    c = c + hist_err[i]\n",
    "                if -i in hist_err.index:\n",
    "                    c = c + hist_err[-i]\n",
    "                d.append(c)\n",
    "            else:\n",
    "                d.append(hist_err[i])\n",
    "        for i in range(len(d)):\n",
    "            log_val = log_val + f\"\\n{i:d} {d[i]:.4f}\"\n",
    "        if file_log:\n",
    "            file_log.write(log_val)\n",
    "        else:\n",
    "            print(log_val)\n",
    "        r2_vals.append(r2)\n",
    "    return r2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfba6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_builder(test_loader):\n",
    "        \n",
    "\n",
    "    def test_1(model, data_loader):\n",
    "    \n",
    "        model.eval()\n",
    "        predicts = []\n",
    "\n",
    "        for imgs in data_loader:\n",
    "        \n",
    "            imgs = imgs.cuda()\n",
    "            pred = model(imgs)\n",
    "\n",
    "            pred_numpy = pred.cpu().detach().numpy()\n",
    "\n",
    "            for class_obj in pred_numpy:\n",
    "                index, max_value = max(enumerate(class_obj), key=lambda i_v: i_v[1])            \n",
    "                predicts.append(index)\n",
    "        \n",
    "        return predicts\n",
    "\n",
    "    \n",
    "\n",
    "    def run_test(model, r2):\n",
    "        predicts = test_1(model, test_loader)\n",
    "\n",
    "\n",
    "        data_1 = [(name, pred) for name, pred in zip(test_df[\"img_num\"].values.tolist(), predicts)]\n",
    "        submit_df = pd.DataFrame(data_1, columns=['img_num', 'number_of_houses'])\n",
    "\n",
    "        #Не забываем добавить 1 к предсказываемому лейблу\n",
    "        submit_df.number_of_houses = submit_df.number_of_houses + 1\n",
    "\n",
    "        submit_df.to_csv(f\"results_log/submit-{r2:.4f}.csv\", index=False)\n",
    "        print(\"DONE!!!\")\n",
    "        \n",
    "    return run_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbadc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler_custom_func(milestone, gamma=0.5, cycle = 10, gamma_pow = None):\n",
    "    def calc_lr(epoch):\n",
    "        if cycle:\n",
    "            e = epoch % cycle +1        \n",
    "        else:\n",
    "            e = epoch\n",
    "        e1 = 1\n",
    "        for v in milestone:\n",
    "            if v <= e:\n",
    "                e1 = e1*gamma        \n",
    "        if gamma_pow:\n",
    "            for v in gamma_pow:\n",
    "                if v <= epoch:\n",
    "                    e1 = e1*gamma\n",
    "        return e1\n",
    "    return calc_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2303446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# читаем датасет\n",
    "data_df = pd.read_csv(base_path+f\"/{train_alias}.csv\")\n",
    "# Нам придется вычесть 1 что индексы классов начинались с 0.\n",
    "data_df.number_of_houses = data_df.number_of_houses- 1\n",
    "\n",
    "data_df = data_df[data_df.number_of_houses < 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b10a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def custom_dataset_split(data_df, test_size, random_state):\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    valid_lst = []\n",
    "    train_lst = []\n",
    "\n",
    "    part_valid = test_size\n",
    "\n",
    "    flag_train = False\n",
    "\n",
    "    for i in range(len(data_df)):\n",
    "        image_name, label = data_df.iloc[i]['img_num'], data_df.iloc[i]['number_of_houses']    \n",
    "        if not(\"_\" in image_name):\n",
    "            r = random.random()\n",
    "            if r <= part_valid:\n",
    "                flag_train = False\n",
    "                valid_lst.append({'img_num':image_name, 'number_of_houses':label})\n",
    "            else:\n",
    "                flag_train = True\n",
    "                train_lst.append({'img_num':image_name, 'number_of_houses':label})\n",
    "        else:\n",
    "            if flag_train:\n",
    "                train_lst.append({'img_num':image_name, 'number_of_houses':label})\n",
    "\n",
    "    print(len(data_df),\":\" ,len(train_lst),\"+\",len(valid_lst),'x11 =',len(train_lst)+len(valid_lst)*11)  \n",
    "\n",
    "    train_df = pd.DataFrame(train_lst, columns = ['img_num','number_of_houses'])\n",
    "    #print(train_df.head(5))\n",
    "    train_df = train_df.reindex(np.random.permutation(train_df.index))\n",
    "    #print(train_df.head(5))\n",
    "    valid_df = pd.DataFrame(valid_lst, columns = ['img_num','number_of_houses'])\n",
    "    return train_df, valid_df\n",
    "\n",
    "# разделим датасет на трейн и валидацию, чтобы смотреть на качество\n",
    "if train_alias == 'train':\n",
    "    train_df, valid_df = train_test_split(data_df, test_size=0.2, random_state=43)\n",
    "if train_alias == 'train_a':\n",
    "    train_df, valid_df = custom_dataset_split(data_df, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5c7d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(initial_seed)\n",
    "\n",
    "if (train_alias == 'train'):\n",
    "    train_dataset = ImageDataset(train_df, train_alias, transform_train)\n",
    "else:\n",
    "    train_dataset = ImageDataset(train_df, train_alias, transform_valid)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=36,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,                                           \n",
    "                                           num_workers=num_workers,\n",
    "                                           worker_init_fn=seed_worker,\n",
    "                                           generator=g\n",
    "                                          )\n",
    "\n",
    "\n",
    "valid_dataset = ImageDataset(valid_df, train_alias ,transform_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                           batch_size=36,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=num_workers,                                           )\n",
    "\n",
    "test_dataset = TestImageDataset(test_df, transform_valid)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=1,\n",
    "                                           # shuffle=True,\n",
    "                                           pin_memory = True,\n",
    "                                           num_workers = num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cadd641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [10:46<00:00, 16.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00015625\n",
      "Train loss: 2.076061317873769\n",
      "Val loss: 6.888976608003889\n",
      "Train acc: tensor(79.4275, device='cuda:0')\n",
      "Val acc: tensor(30.0000, device='cuda:0')\n",
      "D:  [126. 107.  83.  51.  28.  13.   4.   4.   2.   1.   1.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.]\n",
      "===ERR===\n",
      "        c          b\n",
      "0 0.3 0.2785714285714286\n",
      "1 0.5547619047619048 0.611904761904762\n",
      "2 0.7523809523809524 0.7976190476190477\n",
      "3 0.8738095238095238 0.8952380952380953\n",
      "4 0.9404761904761905 0.9476190476190476\n",
      "5 0.9714285714285714 0.9714285714285714\n",
      "SUROGAT-R2: 2.32\n",
      "SUROGAT-R2_best: 2.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/user/torch111/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/user/torch111/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/user/torch111/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/user/torch111/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!!!\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.5\n",
    "\n",
    "lr_list = [0.01]\n",
    "epoch_lst = [40]\n",
    "momentum_lst = [0.93]\n",
    "milestone_lst = [[2,4,8,16,20, 30]]\n",
    "gamma_pow_lst = [None]\n",
    "cycle_lst = [None] \n",
    "weight_decay=0\n",
    "\n",
    "\n",
    "fp = open('results_log/result_log', 'w')\n",
    "fp.write(\"\\n\")\n",
    "fp.close()\n",
    "\n",
    "best_r2 = -10;\n",
    "\n",
    "for lr in lr_list:\n",
    "    for epoch in epoch_lst:\n",
    "        for momentum in momentum_lst:\n",
    "            for milestone in milestone_lst:\n",
    "                for gamma_pow in gamma_pow_lst:\n",
    "                    for cycle in cycle_lst:\n",
    "                        \n",
    "                        seed_worker(0)\n",
    "                        \n",
    "                        train_loss_log, train_acc_log, val_loss_log, val_acc_log, best_model_attr , model = run_fit_model(train_loader, valid_loader, lr, epoch, momentum, milestone, gamma, cycle, gamma_pow, weight_decay = weight_decay)\n",
    "                        \n",
    "                        fp = open('results_log/result_log', 'a')\n",
    "                        fp.write(\"\\nepoch: \"+str(epoch)+\"  momentum:\"+str(momentum)+\"  milestone:\"+str(milestone)+\" gamma_pow:\"+str(gamma_pow)+\" cycle:\" + str(cycle))\n",
    "                        \n",
    "                        lst_models = []\n",
    "                        best_model = best_model_attr[1]\n",
    "                        lst_models.append(best_model)\n",
    "                        \n",
    "                        curr_model = model.to('cpu')\n",
    "                        lst_models.append(curr_model)\n",
    "                        \n",
    "                        r2_vals = valid_models(lst_models, valid_loader, fp)                                            \n",
    "                                                                    \n",
    "                        fp.close()\n",
    "                        \n",
    "                        for i in range(len(lst_models)):\n",
    "                            if r2_vals[i] > best_r2:\n",
    "                                torch.cuda.empty_cache()\n",
    "                                model_1 = lst_models[i]\n",
    "                                model_1.to(\"cuda:0\")\n",
    "                                execute_test = test_builder(test_loader)\n",
    "                                execute_test(model_1, r2_vals[i])\n",
    "                                best_r2 = r2_vals[i]\n",
    "                                torch.save(model_1, f'models_log/model-{best_r2:.4f}.pth')\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0882249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"r2_srg:\", best_model_attr[0])\n",
    "\n",
    "#lst_models = []\n",
    "#best_model = best_model_attr[1]\n",
    "#lst_models.append(best_model)\n",
    "\n",
    "#torch.save(best_model, 'best_model.pth')\n",
    "\n",
    "#curr_model = model.to('cpu')\n",
    "#lst_models.append(curr_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "589b0933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#model = best_model\n",
    "#model.to(\"cuda:0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
